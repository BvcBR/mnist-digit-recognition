{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d198bc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Epoch's\n",
      "0.5376285314559937\n",
      "2 Epoch's\n",
      "0.11607526242733002\n",
      "3 Epoch's\n",
      "0.01244540885090828\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torch.optim as optim  # Import optimizer module\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the datasets\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=lambda y: torch.tensor(y, dtype=torch.long)  # Convert label to integer tensor\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=lambda y: torch.tensor(y, dtype=torch.long)  # Convert label to integer tensor\n",
    ")\n",
    "\n",
    "# Define your neural network\n",
    "class MyFirstNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyFirstNeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "       # Define a sequential container of layers.\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # First linear layer: input features from 28*28 to 512 hidden units.\n",
    "            nn.ReLU(),              # Apply ReLU activation function to add non-linearity.\n",
    "            nn.Linear(512, 512),    # Second linear layer: 512 hidden units to 512 hidden units.\n",
    "            nn.ReLU(),              # Apply ReLU activation function again.\n",
    "            nn.Linear(512, 10),     # Third linear layer: 512 hidden units to 10 output classes.\n",
    ")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Create an instance of the model and move it to the appropriate device\n",
    "model = MyFirstNeuralNetwork().to(device)\n",
    "\n",
    "# Define the optimizer, I chose the Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 3\n",
    "\n",
    "# Training loop\n",
    "for e in range(1,epochs + 1):\n",
    "    print(f\"{e} Epoch's\")\n",
    "    lossi = 0.0\n",
    "    \n",
    "    for input, label in train_loader:\n",
    "        input, label = input.to(device), label.to(device)  # Move input and labels to device\n",
    "        logits = model(input)\n",
    "        loss = loss_fn(logits, label)  # Calculate the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        lossi = loss.item()\n",
    "    print(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2364b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 94.09%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
    "    for input, label in test_loader:\n",
    "        input, label = input.to(device), label.to(device)  # Move input and labels to device\n",
    "        logits = model(input)\n",
    "        _, predicted = torch.max(logits, 1)  # Get the predicted class with highest probability\n",
    "        total += label.size(0)  # Increment the total number of samples\n",
    "        correct += (predicted == label).sum().item()  # Increment the number of correctly predicted samples\n",
    "\n",
    "print(f\"Accuracy on the test set: {(correct / total) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caeaf22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct label for sample: 9\n",
      "Predicted number: 9\n"
     ]
    }
   ],
   "source": [
    "#Sampling a prediction on a single digit\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "random_number = random.randint(1, 1000)\n",
    "image, label = test_data[random_number]\n",
    "image = image.squeeze().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f'Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "X = test_data[random_number][0]\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Correct label for sample: {label}\")\n",
    "print(f\"Predicted number: {y_pred.data.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b71be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab54af0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
