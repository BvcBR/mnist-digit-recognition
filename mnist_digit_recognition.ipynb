{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d198bc10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Epoch's\n",
      "0.6240231990814209\n",
      "2 Epoch's\n",
      "0.3724310100078583\n",
      "3 Epoch's\n",
      "0.3243069052696228\n",
      "4 Epoch's\n",
      "0.14301349222660065\n",
      "5 Epoch's\n",
      "0.3691643178462982\n",
      "6 Epoch's\n",
      "0.3031623959541321\n",
      "7 Epoch's\n",
      "0.17339789867401123\n",
      "8 Epoch's\n",
      "0.3420533537864685\n",
      "9 Epoch's\n",
      "0.23883162438869476\n",
      "10 Epoch's\n",
      "0.24419434368610382\n",
      "11 Epoch's\n",
      "0.42739665508270264\n",
      "12 Epoch's\n",
      "0.16884590685367584\n",
      "13 Epoch's\n",
      "0.03930376470088959\n",
      "14 Epoch's\n",
      "0.15689893066883087\n",
      "15 Epoch's\n",
      "0.12328866124153137\n",
      "16 Epoch's\n",
      "0.08547281473875046\n",
      "17 Epoch's\n",
      "0.0953216552734375\n",
      "18 Epoch's\n",
      "0.04216470569372177\n",
      "19 Epoch's\n",
      "0.01774359680712223\n",
      "20 Epoch's\n",
      "0.03181561455130577\n",
      "21 Epoch's\n",
      "0.03947944939136505\n",
      "22 Epoch's\n",
      "0.04376878961920738\n",
      "23 Epoch's\n",
      "0.03673981502652168\n",
      "24 Epoch's\n",
      "0.14278116822242737\n",
      "25 Epoch's\n",
      "0.36678144335746765\n",
      "26 Epoch's\n",
      "0.16742488741874695\n",
      "27 Epoch's\n",
      "0.13095606863498688\n",
      "28 Epoch's\n",
      "0.027939829975366592\n",
      "29 Epoch's\n",
      "0.03645870462059975\n",
      "30 Epoch's\n",
      "0.04641789197921753\n",
      "31 Epoch's\n",
      "0.06636197865009308\n",
      "32 Epoch's\n",
      "0.13271409273147583\n",
      "33 Epoch's\n",
      "0.15099191665649414\n",
      "34 Epoch's\n",
      "0.12223001569509506\n",
      "35 Epoch's\n",
      "0.01583632454276085\n",
      "36 Epoch's\n",
      "0.052041176706552505\n",
      "37 Epoch's\n",
      "0.0059884702786803246\n",
      "38 Epoch's\n",
      "0.03451294079422951\n",
      "39 Epoch's\n",
      "0.10796675831079483\n",
      "40 Epoch's\n",
      "0.016268398612737656\n",
      "41 Epoch's\n",
      "0.04324725270271301\n",
      "42 Epoch's\n",
      "0.044381532818078995\n",
      "43 Epoch's\n",
      "0.08063128590583801\n",
      "44 Epoch's\n",
      "0.01763027533888817\n",
      "45 Epoch's\n",
      "0.12888480722904205\n",
      "46 Epoch's\n",
      "0.01178757380694151\n",
      "47 Epoch's\n",
      "0.04140932485461235\n",
      "48 Epoch's\n",
      "0.05448098108172417\n",
      "49 Epoch's\n",
      "0.016011957079172134\n",
      "50 Epoch's\n",
      "0.015179387293756008\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import torch.optim as optim  # Import optimizer module\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the datasets\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=lambda y: torch.tensor(y, dtype=torch.long)  # Convert label to integer tensor\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=lambda y: torch.tensor(y, dtype=torch.long)  # Convert label to integer tensor\n",
    ")\n",
    "\n",
    "# Define your neural network\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "       # Define a sequential container of layers.\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # First linear layer: input features from 28*28 to 512 hidden units.\n",
    "            nn.ReLU(),              # Apply ReLU activation function to add non-linearity.\n",
    "            nn.Linear(512, 512),    # Second linear layer: 512 hidden units to 512 hidden units.\n",
    "            nn.ReLU(),              # Apply ReLU activation function again.\n",
    "            nn.Linear(512, 10),     # Third linear layer: 512 hidden units to 10 output classes.\n",
    ")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Create an instance of the model and move it to the appropriate device\n",
    "model = MyNeuralNetwork().to(device)\n",
    "\n",
    "# Define the optimizer, I chose the Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# Training loop\n",
    "for e in range(1,epochs + 1):\n",
    "    print(f\"{e} Epoch's\")\n",
    "    lossi = 0.0\n",
    "    \n",
    "    for input, label in train_loader:\n",
    "        input, label = input.to(device), label.to(device)  # Move input and labels to device\n",
    "        logits = model(input)\n",
    "        loss = loss_fn(logits, label)  # Calculate the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        lossi = loss.item()\n",
    "    print(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2364b6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 97.76%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
    "    for input, label in test_loader:\n",
    "        input, label = input.to(device), label.to(device)  # Move input and labels to device\n",
    "        logits = model(input)\n",
    "        _, predicted = torch.max(logits, 1)  # Get the predicted class with highest probability\n",
    "        total += label.size(0)  # Increment the total number of samples\n",
    "        correct += (predicted == label).sum().item()  # Increment the number of correctly predicted samples\n",
    "\n",
    "print(f\"Accuracy on the test set: {(correct / total) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caeaf22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct label for sample: 4\n",
      "Predicted number: 4\n"
     ]
    }
   ],
   "source": [
    "#Sampling a prediction on a single digit\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "random_number = random.randint(1, 1000)\n",
    "image, label = test_data[random_number]\n",
    "image = image.squeeze().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f'Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "X = test_data[random_number][0]\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Correct label for sample: {label}\")\n",
    "print(f\"Predicted number: {y_pred.data.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
